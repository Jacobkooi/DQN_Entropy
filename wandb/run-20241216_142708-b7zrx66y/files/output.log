Random seed set as 1
Number of rewards collected:  513 Initial buffer size:  20088
Percentage chance of positive reward:  2.553763440860215
/home/jacobk/PycharmProjects/Entropy_final/.venv/lib/python3.8/site-packages/torch/_inductor/compile_fx.py:150: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
The AVERAGE REWARD is: -4.460999999999998
The PERCENTAGE OF SOLVED EPISODES is: 0.0 %
Iterations 0
Iteration:  0 Time:  3.745199203491211
Iterations 500
Iterations 1000
Iterations 1500
Iterations 2000
Iterations 2500
Iterations 3000
Iterations 3500
Iterations 4000
Iterations 4500
Iterations 5000
Iteration:  5000 Time:  21.214641332626343
Iterations 5500
Iterations 6000
Iterations 6500
Iterations 7000
Iterations 7500
Iterations 8000
Iterations 8500
Iterations 9000
Iterations 9500
The AVERAGE REWARD is: -3.060000000000002
The PERCENTAGE OF SOLVED EPISODES is: 13.0 %
Iterations 10000
Iteration:  10000 Time:  22.023741960525513
Iterations 10500
Iterations 11000
Iterations 11500
Iterations 12000
Iterations 12500
Iterations 13000
Iterations 13500
Iterations 14000
Iterations 14500
Iterations 15000
Iteration:  15000 Time:  20.284738779067993
Iterations 15500
Iterations 16000
Iterations 16500
Iterations 17000
Iterations 17500
Iterations 18000
Iterations 18500
Iterations 19000
Iterations 19500
The AVERAGE REWARD is: -3.081000000000003
The PERCENTAGE OF SOLVED EPISODES is: 10.0 %
Iterations 20000
Iteration:  20000 Time:  22.926824808120728
Iterations 20500
Traceback (most recent call last):
  File "main_reward_finding_basic.py", line 90, in <module>
    agent.run_agent()
  File "/home/jacobk/PycharmProjects/Entropy_final/agents/unsupervised_agent_reward_finding_basic.py", line 278, in run_agent
    self.mlp_learn()
  File "/home/jacobk/PycharmProjects/Entropy_final/agents/unsupervised_agent_reward_finding_basic.py", line 137, in mlp_learn
    ACTION = F.one_hot(ACTION.squeeze(1).long(), num_classes=self.action_dim)
KeyboardInterrupt
