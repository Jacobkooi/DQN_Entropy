_wandb:
    value:
        cli_version: 0.19.1
        m:
            - "1": latent_entropy
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": entropy_iterations
              "6":
                - 3
              "7": []
            - "1": global_iterations
              "6":
                - 3
              "7": []
            - "1": average_reward
              "5": 3
              "6":
                - 1
                - 3
              "7": []
            - "1": q_loss
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": mean_latent
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": std_latent
              "5": 2
              "6":
                - 1
                - 3
              "7": []
        python_version: 3.8.10
        t:
            "1":
                - 1
                - 55
            "2":
                - 1
                - 55
            "3":
                - 7
                - 16
                - 23
                - 55
            "4": 3.8.10
            "5": 0.19.1
            "8":
                - 5
            "12": 0.19.1
            "13": linux-x86_64
GPU:
    value: "0"
activation:
    value: tanh
batch_entropy_scaler:
    value: 1
batch_size:
    value: 32
dqn_architecture:
    value: shallow
dqn_scaler:
    value: 8
eps:
    value: 0.1
eps_start:
    value: 0.1
fill_buffer:
    value: 20000
format:
    value: png
gain:
    value: 5
gamma:
    value: 0.85
interval_iterations:
    value: 10000
iterations:
    value: 200000
latent_dim:
    value: 512
lr_dqn:
    value: 5e-05
lr_encoder:
    value: 5e-05
map_type:
    value: random_with_rewards
maze_rewards:
    value: 3
maze_size:
    value: 8
reward_scaler:
    value: 1
run_description:
    value: test_fourmaze
seed:
    value: 1
subsequent:
    value: 1
tau:
    value: 0.02
